{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f519a87",
   "metadata": {},
   "source": [
    "# WSI Feature Extraction Pipeline\n",
    "\n",
    "This notebook demonstrates how to extract and save patch features from Whole Slide Images (WSIs) using a custom pipeline manager that tracks processing status and only performs missing operations.\n",
    "\n",
    "## Key Features:\n",
    "- **Smart State Management**: Tracks which slides have completed segmentation and feature extraction\n",
    "- **Resume Capability**: Only processes missing operations, avoiding redundant computation\n",
    "- **Organized Output Structure**: Logical folder hierarchy for different processing stages\n",
    "- **Professional Implementation**: Clean, maintainable code with proper error handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2cb86b",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries and Custom Module\n",
    "\n",
    "First, we'll import the necessary libraries and our custom pipeline manager module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506e76c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "# Import our custom pipeline manager\n",
    "from trident_pipeline_manager import PipelineManager, PipelineConfig\n",
    "\n",
    "# Set up device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Display GPU information if available\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e111e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "\n",
    "adata = sc.read_h5ad('/equilibrium/datasets/TCGA-histological-data/WSI/data/processed/TCGA-BF-A1PU-01Z-00-DX1.CB0A52E3-16A9-46B2-BBE1-149A6CAAB9CF.h5ad.gz/TCGA-BF-A1PU-01Z-00-DX1.CB0A52E3-16A9-46B2-BBE1-149A6CAAB9CF.h5ad.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c70137",
   "metadata": {},
   "source": [
    "## 2. Initialize Manager and Set Up Paths\n",
    "\n",
    "Configure the pipeline parameters and initialize the manager with your WSI directory and output paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092993d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - Update these paths according to your setup\n",
    "WSI_DIR = \"/equilibrium/datasets/TCGA-histological-data/WSI/raw\"  # Directory containing your WSI files\n",
    "OUTPUT_DIR = \"/equilibrium/datasets/TCGA-histological-data/WSI/interim\"  # Directory to save all outputs\n",
    "WSI_EXTENSIONS = ['.svs', '.tiff', '.tif', '.ndpi', '.mrxs']  # Supported WSI formats\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Configure pipeline parameters\n",
    "config = PipelineConfig(\n",
    "    # Segmentation parameters\n",
    "    segmenter='hest',           # Options: 'hest', 'grandqc'\n",
    "    seg_conf_thresh=0.5,        # Confidence threshold for segmentation\n",
    "    remove_holes=False,         # Whether to remove holes in tissue\n",
    "    remove_artifacts=False,     # Whether to remove artifacts\n",
    "    \n",
    "    # Patching parameters  \n",
    "    mag=20,                     # Magnification (5, 10, 20, 40, 80)\n",
    "    patch_size=512,             # Patch size in pixels\n",
    "    overlap=0,                  # Overlap between patches\n",
    "    min_tissue_proportion=0.0,  # Minimum tissue proportion to keep patch\n",
    "    \n",
    "    # Feature extraction parameters\n",
    "    patch_encoder='conch_v15',  # Available encoders: conch_v15, uni_v1, uni_v2, etc.\n",
    "    \n",
    "    # Processing parameters\n",
    "    batch_size=32,              # Batch size for processing\n",
    "    gpu=0,                      # GPU index to use\n",
    "    skip_errors=True            # Skip errored slides and continue\n",
    ")\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  WSI Directory: {WSI_DIR}\")\n",
    "print(f\"  Output Directory: {OUTPUT_DIR}\")\n",
    "print(f\"  Patch Encoder: {config.patch_encoder}\")\n",
    "print(f\"  Magnification: {config.mag}x\")\n",
    "print(f\"  Patch Size: {config.patch_size}px\")\n",
    "print(f\"  Batch Size: {config.batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d018c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the pipeline manager\n",
    "pipeline_manager = PipelineManager(\n",
    "    job_dir=OUTPUT_DIR,\n",
    "    wsi_dir=WSI_DIR,\n",
    "    config=config,\n",
    "    wsi_ext=WSI_EXTENSIONS\n",
    ")\n",
    "\n",
    "print(\"Pipeline Manager initialized successfully!\")\n",
    "print(f\"Output directory structure created at: {OUTPUT_DIR}\")\n",
    "print(f\"  - Segmentation: {pipeline_manager.seg_dir}\")\n",
    "print(f\"  - Coordinates: {pipeline_manager.coords_dir}\")\n",
    "print(f\"  - Features: {pipeline_manager.features_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c9989e",
   "metadata": {},
   "source": [
    "## 3. Scan Slides and Check Processing Status\n",
    "\n",
    "Discover all WSI files and check the current processing status for each slide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b3a943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discover all WSI samples in the directory\n",
    "sample_ids = pipeline_manager.discover_samples()\n",
    "print(f\"Found {len(sample_ids)} WSI samples:\")\n",
    "for i, sample_id in enumerate(sample_ids[:5]):  # Show first 5 samples\n",
    "    print(f\"  {i+1}. {sample_id}\")\n",
    "if len(sample_ids) > 5:\n",
    "    print(f\"  ... and {len(sample_ids) - 5} more\")\n",
    "\n",
    "# Display current processing status\n",
    "pipeline_manager.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba60822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which samples need processing for each task\n",
    "seg_pending = pipeline_manager.get_pending_samples(\"segmentation\")\n",
    "coords_pending = pipeline_manager.get_pending_samples(\"coordinates\")\n",
    "feat_pending = pipeline_manager.get_pending_samples(\"features\")\n",
    "\n",
    "print(\"\\nDetailed Status:\")\n",
    "print(f\"Samples needing segmentation: {len(seg_pending)}\")\n",
    "print(f\"Samples needing coordinates: {len(coords_pending)}\")\n",
    "print(f\"Samples needing features: {len(feat_pending)}\")\n",
    "\n",
    "# Create a status DataFrame for better visualization\n",
    "status_data = []\n",
    "for sample_id in sample_ids:\n",
    "    sample_state = pipeline_manager.samples[sample_id]\n",
    "    status_data.append({\n",
    "        'Sample ID': sample_id,\n",
    "        'Segmentation': '✓' if sample_state.segmentation_done else '✗',\n",
    "        'Coordinates': '✓' if sample_state.coordinates_done else '✗',\n",
    "        'Features': '✓' if sample_state.features_done else '✗',\n",
    "        'Last Updated': sample_state.last_updated.split('T')[0] if sample_state.last_updated else 'Never'\n",
    "    })\n",
    "\n",
    "status_df = pd.DataFrame(status_data)\n",
    "print(\"\\nSample Status Table:\")\n",
    "print(status_df.head(10))  # Show first 10 samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35db88b5",
   "metadata": {},
   "source": [
    "## 4. Run Segmentation Where Needed\n",
    "\n",
    "Perform tissue segmentation only on slides that haven't been processed yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85fea2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run segmentation for samples that need it\n",
    "if seg_pending:\n",
    "    print(f\"Running segmentation for {len(seg_pending)} samples...\")\n",
    "    print(\"This may take several minutes depending on the number of slides and their size.\")\n",
    "    \n",
    "    try:\n",
    "        # Run segmentation\n",
    "        processed_count = pipeline_manager.run_segmentation(seg_pending)\n",
    "        print(f\"Segmentation completed for {processed_count} samples.\")\n",
    "        if processed_count < len(seg_pending):\n",
    "            print(f\"Warning: {len(seg_pending) - processed_count} samples failed to segment. Check logs for details.\")\n",
    "            pipeline_manager.force_refresh_state()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during segmentation: {e}\")\n",
    "        print(\"Forcing a state refresh to accurately reflect the pipeline status.\")\n",
    "        pipeline_manager.force_refresh_state()\n",
    "    finally:\n",
    "        # Update status\n",
    "        pipeline_manager.print_summary()\n",
    "else:\n",
    "    print(\"All samples already have segmentation completed! ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcbe224",
   "metadata": {},
   "source": [
    "## 5. Run Coordinate Extraction Where Needed\n",
    "\n",
    "Extract patch coordinates for slides that haven't been processed yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dd4e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run coordinate extraction for samples that need it\n",
    "coords_pending = pipeline_manager.get_pending_samples(\"coordinates\")  # Refresh the list\n",
    "\n",
    "if coords_pending:\n",
    "    print(f\"Running coordinate extraction for {len(coords_pending)} samples...\")\n",
    "    print(\"This step identifies tissue regions and extracts patch coordinates.\")\n",
    "    \n",
    "    # Run coordinate extraction\n",
    "    processed_count = pipeline_manager.run_coordinate_extraction(coords_pending)\n",
    "    print(f\"Coordinate extraction completed for {processed_count} samples.\")\n",
    "    \n",
    "    # Update status\n",
    "    pipeline_manager.print_summary()\n",
    "else:\n",
    "    print(\"All samples already have coordinates extracted! ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d0b01a",
   "metadata": {},
   "source": [
    "## 6. Run Patch Feature Extraction Where Needed\n",
    "\n",
    "Extract patch features using the configured patch encoder for slides that haven't been processed yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a89385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run feature extraction for samples that need it\n",
    "feat_pending = pipeline_manager.get_pending_samples(\"features\")  # Refresh the list\n",
    "\n",
    "if feat_pending:\n",
    "    print(f\"Running feature extraction for {len(feat_pending)} samples...\")\n",
    "    print(f\"Using patch encoder: {config.patch_encoder}\")\n",
    "    print(\"This is the most computationally intensive step and may take considerable time.\")\n",
    "    \n",
    "    # Run feature extraction\n",
    "    processed_count = pipeline_manager.run_feature_extraction(feat_pending)\n",
    "    print(f\"Feature extraction completed for {processed_count} samples.\")\n",
    "    \n",
    "    # Update status\n",
    "    pipeline_manager.print_summary()\n",
    "else:\n",
    "    print(\"All samples already have features extracted! ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b2b340",
   "metadata": {},
   "source": [
    "## Usage Notes\n",
    "\n",
    "### Key Features:\n",
    "- **Resume Capability**: The pipeline tracks processing state and only runs missing operations\n",
    "- **Organized Output**: Clean directory structure with logical naming conventions\n",
    "- **Error Handling**: Continues processing even if individual slides fail\n",
    "- **Flexible Configuration**: Easy to modify parameters for different use cases\n",
    "\n",
    "### Output Files:\n",
    "- **Segmentation**: `.h5` files containing tissue masks and contours\n",
    "- **Coordinates**: `.h5` files containing patch coordinates and metadata\n",
    "- **Features**: `.h5` files containing patch-level feature embeddings\n",
    "- **State Tracking**: `pipeline_state.json` maintains processing status\n",
    "\n",
    "### Tips:\n",
    "1. **Memory Management**: Adjust `batch_size` based on your GPU memory\n",
    "2. **Storage**: Ensure sufficient disk space for feature files (can be large)\n",
    "3. **Resumption**: You can safely restart the notebook - it will skip completed steps\n",
    "4. **Monitoring**: Check the summary output to track progress\n",
    "\n",
    "### Next Steps:\n",
    "With the extracted features, you can:\n",
    "- Train slide-level classification models\n",
    "- Perform clustering analysis\n",
    "- Generate attention heatmaps\n",
    "- Build retrieval systems"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
