{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4e95087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "\n",
    "# Remove any cached modules\n",
    "if 'src.ucb_kd_trainer' in sys.modules:\n",
    "    del sys.modules['src.ucb_kd_trainer']\n",
    "\n",
    "import datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from datasets import load_dataset\n",
    "from src.ABMIL_UCB import ABMIL_UCB\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "from src.ucb_kd_trainer import ABMILUCBTrainingArguments, ABMILFeatureDataset, create_abmil_ucb_trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1e45904",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_from_disk('/equilibrium/datasets/TCGA-histological-data/huggingfac/KN_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d60549a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ABMILFeatureDataset(dataset['train']['features'], dataset['train']['targets'], num_features=512)\n",
    "test_dataset = ABMILFeatureDataset(dataset['test']['features'], dataset['test']['targets'], num_features=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "781cd4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ABMIL_UCB(\n",
    "        feature_dim=768,\n",
    "        head_dim=256,\n",
    "        n_heads=8,\n",
    "        dropout=0.2,\n",
    "        n_branches=1,\n",
    "        gated=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "194a0467",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = ABMILUCBTrainingArguments(\n",
    "        output_dir='./results',\n",
    "        num_train_epochs=10,\n",
    "        per_device_train_batch_size=4,\n",
    "        per_device_eval_batch_size=4,\n",
    "        warmup_steps=100,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir='./logs',\n",
    "        logging_steps=10,\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=50,\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=100,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"accuracy\",\n",
    "        greater_is_better=True,\n",
    "        # ABMIL UCB specific parameters\n",
    "        num_features=196,\n",
    "        ucb_enabled=True,\n",
    "        ucb_beta=1.0,\n",
    "        ucb_warmup_iter=500,\n",
    "        ucb_top_k=10,\n",
    "        n_heads=8,\n",
    "        n_branches=1,\n",
    "        remove_unused_columns=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "805aa2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = create_abmil_ucb_trainer(\n",
    "        model=model,\n",
    "        training_args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "599526d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [120/120 00:54, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Mean Similarity</th>\n",
       "      <th>Std Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.173200</td>\n",
       "      <td>0.134890</td>\n",
       "      <td>0.865110</td>\n",
       "      <td>0.865110</td>\n",
       "      <td>0.079289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.078800</td>\n",
       "      <td>0.084468</td>\n",
       "      <td>0.915532</td>\n",
       "      <td>0.915532</td>\n",
       "      <td>0.047065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vcivale/WSI-RL-Tiles-Selection_3/.venv/lib/python3.10/site-packages/torch/nn/modules/linear.py:125: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:181.)\n",
      "  return F.linear(input, self.weight, self.bias)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=120, training_loss=0.27743588040272393, metrics={'train_runtime': 57.7546, 'train_samples_per_second': 16.276, 'train_steps_per_second': 2.078, 'total_flos': 0.0, 'train_loss': 0.27743588040272393, 'epoch': 10.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
